# -*- coding: utf-8 -*-
"""tf.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Z2kqZEuWEYGqumaNE2SkjkNntkoGkSE-
"""

!pip install tensorflow

from tensorflow.python.keras.datasets import imdb
(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = 10000)

print(x_train[0])
print(y_train[0])

from keras.preprocessing.sequence import pad_sequences

class_names = ['Negative', 'Positive']
word_index = imdb.get_word_index()
#print(word_index['hello'])
reverse_word_index = dict((value, key) for key, value in word_index.items())
def decode(review):
    text = ''
    for i in review:
        text += reverse_word_index[i]
        text += ' '
        return text
decode(x_train[0])
def show_lengths():
      print('Length of 1st training example: ', len(x_train[0]))
      print('Length of 2nd training example: ',  len(x_train[1]))
      print('Length of 1st test example: ', len(x_test[0]))
      print('Length of 2nd test example: ',  len(x_test[1]))
      
show_lengths()
word_index['the']
x_train = pad_sequences(x_train, value = word_index['the'], padding = 'post', maxlen = 256)
x_test = pad_sequences(x_test, value = word_index['the'], padding = 'post', maxlen = 256)
show_lengths() 
decode(x_train[0])

from tensorflow.python.keras.models import Sequential
from tensorflow.python.keras.layers import Embedding, Dense, GlobalAveragePooling1D
model = Sequential([
    Embedding(10000, 16),
    GlobalAveragePooling1D(),
    Dense(16, activation = 'relu'),
    Dense(1, activation = 'sigmoid')
    ])
model.compile(
       optimizer = 'adam',
       loss = 'binary_crossentropy',
       metrics = ['acc']
     )

model.summary()   
from tensorflow.python.keras.callbacks import LambdaCallback
simple_logging = LambdaCallback(on_epoch_end = lambda e, l: print(e, end='.'))
E = 20
h = model.fit(
    x_train, y_train,
    validation_split = 0.2,
    epochs = E,
    callbacks = [simple_logging],
    verbose = False
    )

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline
plt.plot(range(E), h.history['acc'], label = 'Training')
plt.plot(range(E), h.history['val_acc'], label = 'Validation')
plt.legend()
plt.show()
loss, acc = model.evaluate(x_test, y_test)
print('Test set accuracy: ', acc * 100)
import numpy as np
prediction = model.predict(np.expand_dims(x_test[0], axis = 0))
class_names = ['Negative', 'Positive']
print(class_names[np.argmax(prediction[0])])
#print(decode(x_test[0]))
#[]

